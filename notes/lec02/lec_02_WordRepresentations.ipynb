{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Model - Word2Vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset : Indian News Articles\n",
    "\n",
    "link : https://www.kaggle.com/datasets/therohk/india-headlines-news-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010102           unknown   \n",
       "1      20010102           unknown   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                Fissures in Hurriyat over Pak visit  \n",
       "2              America's unwanted heading for India?  \n",
       "3                 For bigwigs; it is destination Goa  \n",
       "4               Extra buses to clear tourist traffic  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = np.loadtxt('./data/india-news-headlines.csv', dtype=str)\n",
    "# data = data[1:]\n",
    "df = pd.read_csv('./data/india-news-headlines.csv')\n",
    "df.head( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3876557 entries, 0 to 3876556\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   publish_date       int64 \n",
      " 1   headline_category  object\n",
      " 2   headline_text      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 88.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3850912, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Status quo will not be disturbed at Ayodhya; says Vajpayee',\n",
       " 'Fissures in Hurriyat over Pak visit',\n",
       " \"America's unwanted heading for India?\",\n",
       " 'For bigwigs; it is destination Goa',\n",
       " 'Extra buses to clear tourist traffic']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentances = df['headline_text'].tolist()\n",
    "type(sentances)\n",
    "sentances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['status quo will not be disturbed at ayodhya says vajpayee',\n",
       " 'fissures in hurriyat over pak visit',\n",
       " 'americas unwanted heading for india',\n",
       " 'for bigwigs it is destination goa',\n",
       " 'extra buses to clear tourist traffic']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def pre_process_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    return text\n",
    "\n",
    "sentances = [pre_process_data(text) for text in sentances] \n",
    "sentances[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances = sentances[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128  # Embedding dimension\n",
    "m = 2    # Context window size\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_sentences = [sentence.split() for sentence in sentances]\n",
    "# tokenized_sentences[:4] , len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "# words[:4] , len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_counts = Counter(words)\n",
    "# vocab = {word: idx for idx, (word, _) in enumerate(word_counts.most_common())}\n",
    "# vocab_size = len(vocab)\n",
    "# vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = []\n",
    "# for sentence in tokenized_sentences:\n",
    "#     indices = [vocab[word] for word in sentence]\n",
    "#     for i in range(len(indices)):\n",
    "#         target = indices[i]\n",
    "#         context = indices[max(0, i - m):i] + indices[i + 1:min(len(indices), i + m + 1)]\n",
    "#         for ctx in context:\n",
    "#             pairs.append((target, ctx))\n",
    "# pairs[:4] , len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx2word = {idx: word for word, idx in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274470"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        tokenized_sentences = [sentence.split() for sentence in data]\n",
    "        self.words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "        self.word_counts = Counter(self.words)\n",
    "        self.vocab = {word: idx for idx, (word, _) in enumerate(self.word_counts.most_common())}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.word_dict = {idx: word for word, idx in self.vocab.items()}\n",
    "        \n",
    "        self.pairs = []\n",
    "        for sentence in tokenized_sentences:\n",
    "            indices = [self.vocab[word] for word in sentence]\n",
    "            for i in range(len(indices)):\n",
    "                target = indices[i]\n",
    "                context = indices[max(0, i - m):i] + indices[i + 1:min(len(indices), i + m + 1)]\n",
    "                for ctx in context:\n",
    "                    self.pairs.append((target, ctx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.pairs[idx][0], dtype=torch.long).to(device), torch.tensor(self.pairs[idx][1], dtype=torch.long).to(device)\n",
    "\n",
    "    def idx2word(self, idx):\n",
    "        return self.word_dict[idx]\n",
    "    \n",
    "dataset = SkipGramDataset(sentances)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16115"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.in_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "    def forward(self, target, context):\n",
    "        target_embed = self.in_embed(target) # (batch_size, d)\n",
    "        target_embed = target_embed.to(device)\n",
    "        context_embed = self.out_embed(context)  # (batch_size, d)\n",
    "        context_embed = context_embed.to(device)\n",
    "        scores = torch.matmul(target_embed, context_embed.T)  # (batch_size, batch_size)\n",
    "        return scores\n",
    "\n",
    "model = Word2Vec(dataset.vocab_size, d)\n",
    "model = model.to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 18.6476\n",
      "Epoch 2/2, Loss: 12.7575\n",
      "Embeddings shape: torch.Size([16115, 128])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "epochs = 2\n",
    "start_train = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    start_epoch = datetime.datetime.now()\n",
    "    for target, context in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(target, context)\n",
    "        loss = criterion(scores, torch.arange(len(target)).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    end_epoch = datetime.datetime.now()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f} Time : {end_epoch - start_epoch}\")\n",
    "end_train = datetime.datetime.now()\n",
    "print(f\"Total training time: {end_train - start_train}\")\n",
    "\n",
    "# Get final embeddings\n",
    "embeddings = model.in_embed.weight.data\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8281,  0.2208,  0.2066, -0.3692, -0.2861, -0.5029, -0.9231, -0.0129,\n",
       "        -0.2746,  0.6212, -0.2126, -0.0185,  0.1650, -0.1373,  0.1493,  0.2634,\n",
       "        -0.3162,  0.2602, -0.2889, -0.0176, -0.1919,  0.1611, -0.4257,  0.3053,\n",
       "        -0.1197,  0.8984, -0.3155, -0.3865,  0.1984,  0.2698, -0.1225,  0.1945,\n",
       "        -0.2526, -0.2370,  0.2030,  0.0103, -0.3100,  0.1015, -1.0637,  0.6350,\n",
       "         0.2944,  0.1062, -0.8214, -0.5063,  0.0519,  0.1600,  0.4495,  0.6756,\n",
       "        -0.0444,  0.7521, -0.5282, -0.3213, -0.1128, -0.8681,  0.0423,  0.2985,\n",
       "         0.4212,  0.8281, -0.9976,  0.3831,  0.2669,  0.9346,  0.1325,  0.4874,\n",
       "        -0.2070, -0.1826, -0.1507,  0.3772,  0.6873, -0.3246, -0.0659,  0.7672,\n",
       "         0.3524,  0.5708, -0.4227,  0.0271, -0.3807,  0.8528,  0.0433, -0.2789,\n",
       "         0.7951, -0.4810, -0.1612, -0.2830, -0.4202, -0.3223, -0.4604, -0.3238,\n",
       "        -0.0356,  1.0936, -0.4676,  0.2899,  0.1627, -0.0911,  0.6669, -0.2958,\n",
       "         1.6538,  0.7600, -0.0513, -0.6489,  0.2350, -0.0986,  0.7967,  0.2607,\n",
       "         0.4060,  0.2587, -0.2096,  0.1214, -0.2047, -0.2154, -0.5608,  0.0557,\n",
       "        -0.3838, -0.5291,  0.1953,  0.4016, -0.1947, -0.4898, -0.8411, -0.9462,\n",
       "         0.1620, -0.0855,  0.9769,  0.3272, -0.4377, -0.4385, -0.4150,  0.4333],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"india\"\n",
    "embedding = embeddings[dataset.vocab[word]]\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('testify', 22.02251625061035),\n",
       " ('humiliation', 20.87239646911621),\n",
       " ('e', 20.559024810791016),\n",
       " ('hoitytoity', 20.296947479248047),\n",
       " ('mouma', 20.176151275634766)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar(word, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        vec = embeddings[dataset.vocab[word]]\n",
    "        similarities = torch.matmul(embeddings, vec)\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values[1:], indices[1:])]\n",
    "    \n",
    "find_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trainers', 30.954187393188477),\n",
       " ('priests', 29.73798942565918),\n",
       " ('restriction', 29.651779174804688),\n",
       " ('allegations', 27.303354263305664),\n",
       " ('f', 26.921924591064453)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\"goa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 5.9219 Time : 0:00:58.164656\n",
      "Epoch 2/100, Loss: 4.8245 Time : 0:01:03.099172\n",
      "Epoch 3/100, Loss: 4.0234 Time : 0:00:57.366843\n",
      "Epoch 4/100, Loss: 3.4184 Time : 0:01:04.583211\n",
      "Epoch 5/100, Loss: 2.9561 Time : 0:00:58.608970\n",
      "Epoch 6/100, Loss: 2.6140 Time : 0:01:03.982722\n",
      "Epoch 7/100, Loss: 2.3386 Time : 0:00:54.838242\n",
      "Epoch 8/100, Loss: 2.1318 Time : 0:01:03.527977\n",
      "Epoch 9/100, Loss: 1.9658 Time : 0:00:56.782572\n",
      "Epoch 10/100, Loss: 1.8342 Time : 0:01:02.251838\n",
      "Epoch 11/100, Loss: 1.7314 Time : 0:00:57.739489\n",
      "Epoch 12/100, Loss: 1.6460 Time : 0:01:02.666478\n",
      "Epoch 13/100, Loss: 1.5748 Time : 0:00:55.932510\n",
      "Epoch 14/100, Loss: 1.5190 Time : 0:01:02.170413\n",
      "Epoch 15/100, Loss: 1.4716 Time : 0:00:55.336758\n",
      "Epoch 16/100, Loss: 1.4305 Time : 0:01:03.820962\n",
      "Epoch 17/100, Loss: 1.3986 Time : 0:00:57.933283\n",
      "Epoch 18/100, Loss: 1.3705 Time : 0:01:00.363841\n",
      "Epoch 19/100, Loss: 1.3478 Time : 0:00:56.754024\n",
      "Epoch 20/100, Loss: 1.3255 Time : 0:01:02.396801\n",
      "Epoch 21/100, Loss: 1.3109 Time : 0:00:56.595077\n",
      "Epoch 22/100, Loss: 1.2933 Time : 0:01:02.012648\n",
      "Epoch 23/100, Loss: 1.2806 Time : 0:00:55.504598\n",
      "Epoch 24/100, Loss: 1.2732 Time : 0:01:00.057015\n",
      "Epoch 25/100, Loss: 1.2643 Time : 0:00:58.544394\n",
      "Epoch 26/100, Loss: 1.2591 Time : 0:01:00.360655\n",
      "Epoch 27/100, Loss: 1.2483 Time : 0:00:59.710972\n",
      "Epoch 28/100, Loss: 1.2434 Time : 0:08:48.875689\n",
      "Epoch 29/100, Loss: 1.2389 Time : 0:03:01.545865\n",
      "Epoch 30/100, Loss: 1.2361 Time : 0:01:03.194629\n",
      "Epoch 31/100, Loss: 1.2278 Time : 0:00:58.689572\n",
      "Epoch 32/100, Loss: 1.2273 Time : 0:01:03.054456\n",
      "Epoch 33/100, Loss: 1.2241 Time : 0:00:56.641761\n",
      "Epoch 34/100, Loss: 1.2227 Time : 0:00:53.807926\n",
      "Epoch 35/100, Loss: 1.2172 Time : 0:00:46.072108\n",
      "Epoch 36/100, Loss: 1.2123 Time : 0:00:54.148448\n",
      "Epoch 37/100, Loss: 1.2142 Time : 0:00:57.295273\n",
      "Epoch 38/100, Loss: 1.2125 Time : 0:00:57.672103\n",
      "Epoch 39/100, Loss: 1.2096 Time : 0:00:55.288515\n",
      "Epoch 40/100, Loss: 1.2080 Time : 0:00:56.665838\n",
      "Epoch 41/100, Loss: 1.2075 Time : 0:00:57.101947\n",
      "Epoch 42/100, Loss: 1.2080 Time : 0:00:59.206322\n",
      "Epoch 43/100, Loss: 1.2032 Time : 0:00:59.155863\n",
      "Epoch 44/100, Loss: 1.2042 Time : 0:01:02.122084\n",
      "Epoch 45/100, Loss: 1.2037 Time : 0:01:03.292964\n",
      "Epoch 46/100, Loss: 1.2065 Time : 0:01:01.620635\n",
      "Epoch 47/100, Loss: 1.2044 Time : 0:01:05.469041\n",
      "Epoch 48/100, Loss: 1.2036 Time : 0:01:01.751009\n",
      "Epoch 49/100, Loss: 1.2036 Time : 0:01:01.865451\n",
      "Epoch 50/100, Loss: 1.1991 Time : 0:00:57.661518\n",
      "Epoch 51/100, Loss: 1.2013 Time : 0:00:59.834549\n",
      "Epoch 52/100, Loss: 1.2008 Time : 0:00:57.293855\n",
      "Epoch 53/100, Loss: 1.2017 Time : 0:00:59.386507\n",
      "Epoch 54/100, Loss: 1.1989 Time : 0:00:52.312131\n",
      "Epoch 55/100, Loss: 1.2002 Time : 0:00:57.818945\n",
      "Epoch 56/100, Loss: 1.2018 Time : 0:00:54.532448\n",
      "Epoch 57/100, Loss: 1.2008 Time : 0:01:02.287801\n",
      "Epoch 58/100, Loss: 1.2012 Time : 0:00:54.369650\n",
      "Epoch 59/100, Loss: 1.2022 Time : 0:00:54.896503\n",
      "Epoch 60/100, Loss: 1.2015 Time : 0:01:35.135888\n",
      "Epoch 61/100, Loss: 1.2033 Time : 0:01:19.735310\n",
      "Epoch 62/100, Loss: 1.1985 Time : 0:01:36.769637\n",
      "Epoch 63/100, Loss: 1.1997 Time : 0:01:34.720043\n",
      "Epoch 64/100, Loss: 1.1996 Time : 0:01:19.274299\n",
      "Epoch 65/100, Loss: 1.1996 Time : 0:01:24.928628\n",
      "Epoch 66/100, Loss: 1.1986 Time : 0:01:39.308117\n",
      "Epoch 67/100, Loss: 1.1997 Time : 0:01:32.105799\n",
      "Epoch 68/100, Loss: 1.2015 Time : 0:01:24.536148\n",
      "Epoch 69/100, Loss: 1.2018 Time : 0:01:26.531411\n",
      "Epoch 70/100, Loss: 1.2025 Time : 0:01:37.216773\n",
      "Epoch 71/100, Loss: 1.1992 Time : 0:01:35.481558\n",
      "Epoch 72/100, Loss: 1.2034 Time : 0:01:23.075078\n",
      "Epoch 73/100, Loss: 1.2016 Time : 0:01:24.440876\n",
      "Epoch 74/100, Loss: 1.2019 Time : 0:01:35.624619\n",
      "Epoch 75/100, Loss: 1.1992 Time : 0:01:33.624286\n",
      "Epoch 76/100, Loss: 1.2035 Time : 0:01:22.245889\n",
      "Epoch 77/100, Loss: 1.2031 Time : 0:01:28.608565\n",
      "Epoch 78/100, Loss: 1.1994 Time : 0:01:36.124463\n",
      "Epoch 79/100, Loss: 1.2040 Time : 0:01:34.857609\n",
      "Epoch 80/100, Loss: 1.2001 Time : 0:01:22.241181\n",
      "Epoch 81/100, Loss: 1.2025 Time : 0:01:27.255225\n",
      "Epoch 82/100, Loss: 1.2031 Time : 0:01:36.835242\n",
      "Epoch 83/100, Loss: 1.2040 Time : 0:01:36.559573\n",
      "Epoch 84/100, Loss: 1.2052 Time : 0:01:27.239851\n",
      "Epoch 85/100, Loss: 1.2063 Time : 0:01:21.073045\n",
      "Epoch 86/100, Loss: 1.2069 Time : 0:01:39.394359\n",
      "Epoch 87/100, Loss: 1.2020 Time : 0:01:51.290482\n",
      "Epoch 88/100, Loss: 1.2069 Time : 0:01:03.401970\n",
      "Epoch 89/100, Loss: 1.2088 Time : 0:01:05.499826\n",
      "Epoch 90/100, Loss: 1.2020 Time : 0:00:58.312718\n",
      "Epoch 91/100, Loss: 1.2061 Time : 0:01:00.115089\n",
      "Epoch 92/100, Loss: 1.2016 Time : 0:00:52.048684\n",
      "Epoch 93/100, Loss: 1.2089 Time : 0:00:56.951848\n",
      "Epoch 94/100, Loss: 1.2039 Time : 0:00:51.115030\n",
      "Epoch 95/100, Loss: 1.2092 Time : 0:01:00.454045\n",
      "Epoch 96/100, Loss: 1.2093 Time : 0:00:41.006531\n",
      "Epoch 97/100, Loss: 1.2083 Time : 0:00:50.578544\n",
      "Epoch 98/100, Loss: 1.2100 Time : 0:01:00.432662\n",
      "Epoch 99/100, Loss: 1.2057 Time : 0:00:59.422698\n",
      "Epoch 100/100, Loss: 1.2078 Time : 0:00:54.478137\n",
      "Total training time: 2:02:26.107574\n",
      "Embeddings shape: torch.Size([16115, 128])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "epochs = 100\n",
    "start_train = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    start_epoch = datetime.datetime.now()\n",
    "    for target, context in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(target, context)\n",
    "        loss = criterion(scores, torch.arange(len(target)).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    end_epoch = datetime.datetime.now()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f} Time : {end_epoch - start_epoch}\")\n",
    "end_train = datetime.datetime.now()\n",
    "print(f\"Total training time: {end_train - start_train}\")\n",
    "\n",
    "# Get final embeddings\n",
    "embeddings = model.in_embed.weight.data\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100 epochs\n",
    "* Total training time: 2:02:26.107574\n",
    "* Embeddings shape: torch.Size([16115, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0194,  0.3255,  0.0346,  0.0183,  0.1571,  0.0103, -0.1187,  0.0466,\n",
       "         0.4334,  0.0987, -0.3504, -0.3079, -0.0638,  0.2358,  0.0409,  0.0637,\n",
       "        -0.2056,  0.0773,  0.2327,  0.0081, -0.1010,  0.1506, -0.2580, -0.1388,\n",
       "        -0.1459,  0.3029, -0.0941,  0.0629, -0.3272, -0.4064, -0.3322,  0.4888,\n",
       "         0.0069, -0.0429, -0.3430,  0.2600,  0.0395,  0.0536, -0.2117,  0.1122,\n",
       "         0.1337, -0.0182, -0.0374,  0.2303, -0.0293,  0.0690,  0.1730, -0.2067,\n",
       "        -0.1530,  0.4344, -0.0104, -0.1476,  0.0397,  0.2683,  0.2841,  0.3988,\n",
       "         0.3831,  0.2640, -0.2403,  0.0968, -0.2361,  0.2960,  0.4244,  0.0815,\n",
       "        -0.2283, -0.1886,  0.0197, -0.0378,  0.1208, -0.2162, -0.0120, -0.0064,\n",
       "        -0.0338, -0.0991,  0.1906, -0.1373, -0.1937,  0.2037, -0.5391,  0.0145,\n",
       "        -0.0810,  0.0641, -0.1783, -0.3374, -0.1284,  0.0445,  0.0844, -0.3269,\n",
       "         0.1566,  0.1763, -0.1409,  0.2428,  0.4478,  0.0144,  0.1651, -0.1897,\n",
       "         0.2562,  0.0517,  0.0119, -0.3784,  0.1839,  0.0716,  0.1738,  0.1333,\n",
       "        -0.1189,  0.0563,  0.0170,  0.2123,  0.0846,  0.3172, -0.1436,  0.0371,\n",
       "         0.0385, -0.0881,  0.0870, -0.0918,  0.0753, -0.1784,  0.3104, -0.3132,\n",
       "         0.1009, -0.2969, -0.0463, -0.2171, -0.0913, -0.0601, -0.4225,  0.3867],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"india\"\n",
    "embedding = embeddings[dataset.vocab[word]]\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nawruz', 9.902406692504883),\n",
       " ('singareni', 9.812178611755371),\n",
       " ('septuplets', 9.148886680603027),\n",
       " ('diagnostic', 9.141351699829102),\n",
       " ('plough', 8.840997695922852)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 0.4843333661556244),\n",
       " ('pm', 0.44458457827568054),\n",
       " ('it', 0.4277379512786865),\n",
       " ('talks', 0.41505417227745056),\n",
       " ('its', 0.400892972946167)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_cosine(word, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        vec = embeddings[dataset.vocab[word]]\n",
    "        similarities = torch.matmul(embeddings, vec) / (torch.norm(embeddings, dim=1) * torch.norm(vec))\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values[1:], indices[1:])]\n",
    "\n",
    "find_similar_cosine(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ministers', 0.33838722109794617),\n",
       " ('fashions', 0.3322593569755554),\n",
       " ('set', 0.3311415910720825),\n",
       " ('at', 0.32622039318084717),\n",
       " ('new', 0.3222562074661255)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_cosine(\"goa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 0.4343026280403137),\n",
       " ('as', 0.42826682329177856),\n",
       " ('set', 0.407269150018692),\n",
       " ('down', 0.4007364809513092),\n",
       " ('chief', 0.40044018626213074)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_cosine(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7592395544052124),\n",
       " ('fests', 0.33734554052352905),\n",
       " ('expired', 0.31791630387306213),\n",
       " ('landmine', 0.31200072169303894),\n",
       " ('lethal', 0.29223430156707764),\n",
       " ('2612', 0.2892310321331024)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 =  embeddings[dataset.vocab[\"man\"]]\n",
    "w2 =  embeddings[dataset.vocab[\"king\"]]\n",
    "w3 =  embeddings[dataset.vocab[\"queen\"]]\n",
    "w4 = w1 - w2 + w3\n",
    "def find_similar_cosine_vec(vec, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        similarities = torch.matmul(embeddings, vec) / (torch.norm(embeddings, dim=1) * torch.norm(vec))\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values, indices)]\n",
    "\n",
    "find_similar_cosine_vec(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fests', 0.33734554052352905),\n",
       " ('expired', 0.31791630387306213),\n",
       " ('landmine', 0.31200072169303894),\n",
       " ('lethal', 0.29223430156707764),\n",
       " ('2612', 0.2892310321331024)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(word1, word2, word3):\n",
    "    w1 = embeddings[dataset.vocab[word1]]\n",
    "    w2 = embeddings[dataset.vocab[word2]]\n",
    "    w3 = embeddings[dataset.vocab[word3]]\n",
    "    w4 = w2 - w1 + w3\n",
    "    embs =  find_similar_cosine_vec(w4)\n",
    "    return [emb for emb in embs if emb[0] not in [word1, word2, word3]] \n",
    "\n",
    "analogy(\"king\", \"man\" ,\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = './model_parameters/'\n",
    "# np.save(folder + 'embeddings.npy', embeddings.cpu().numpy()) \n",
    "# np.save(folder + 'vocab.npy', dataset.vocab)\n",
    "# np.save(folder + 'word_dict.npy', dataset.word_dict)\n",
    "# np.save(folder + 'word_counts.npy', dataset.word_counts)\n",
    "# np.save(folder + 'pairs.npy', dataset.pairs)\n",
    "# np.save(folder + 'words.npy', dataset.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './model_parameters/'\n",
    "embeddings = torch.tensor(np.load(folder + 'embeddings.npy')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram - pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading word2vec-google-news-300...\n",
      "Model downloaded successfully to: C:\\Users\\myalla/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "def download_word2vec_model(model_name=\"word2vec-google-news-300\"):\n",
    "    try:\n",
    "        # Check if model is available\n",
    "        available_models = api.info()['models'].keys()\n",
    "        if model_name not in available_models:\n",
    "            raise ValueError(\n",
    "                f\"Model '{model_name}' not found. Available models: {', '.join(available_models)}\"\n",
    "            )\n",
    "\n",
    "        print(f\"Downloading {model_name}...\")\n",
    "        model_path = api.load(model_name, return_path=True)\n",
    "        print(f\"Model downloaded successfully to: {model_path}\")\n",
    "\n",
    "        return model_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "word2vec_path = download_word2vec_model()\n",
    "embeddings = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indian', 0.6967039704322815),\n",
       " ('usa', 0.6836211085319519),\n",
       " ('pakistan', 0.681516706943512),\n",
       " ('chennai', 0.6675503253936768),\n",
       " ('america', 0.6589399576187134),\n",
       " ('sri_lanka', 0.64982008934021),\n",
       " ('canada', 0.6490967869758606),\n",
       " ('australia', 0.6368584036827087),\n",
       " ('mexico', 0.6239137649536133),\n",
       " ('uk', 0.6221641898155212)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300517559051514),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676352500916),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613663792610168),\n",
       " ('sultan', 0.5376775860786438),\n",
       " ('Queen_Consort', 0.5344247817993164),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = embeddings.get_vector(\"king\")\n",
    "w2 = embeddings.get_vector(\"man\")\n",
    "w3 = embeddings.get_vector(\"woman\")\n",
    "\n",
    "w4 = w1 - w2 + w3\n",
    "\n",
    "embeddings.similar_by_vector(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7186801433563232),\n",
       " ('girl', 0.5882835388183594),\n",
       " ('lady', 0.5754351615905762),\n",
       " ('teenage_girl', 0.5700528025627136),\n",
       " ('teenager', 0.5378326177597046),\n",
       " ('schoolgirl', 0.497780978679657),\n",
       " ('policewoman', 0.49065014719963074),\n",
       " ('blonde', 0.4870774745941162),\n",
       " ('redhead', 0.4778464436531067)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy_gensim(word1, word2, word3):\n",
    "    w1 = embeddings.get_vector(word1)\n",
    "    w2 = embeddings.get_vector(word2)\n",
    "    w3 = embeddings.get_vector(word3)\n",
    "    w4 = w2 - w1 + w3\n",
    "    embs =  embeddings.similar_by_vector(w4)\n",
    "    return [emb for emb in embs if emb[0] not in [word1, word2, word3]] \n",
    "\n",
    "analogy_gensim(\"king\", \"man\" ,\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('japan', 0.5214436054229736),\n",
       " ('hong_kong', 0.46592071652412415),\n",
       " ('japanese', 0.4565887153148651)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('rupee', 0.6182144284248352),\n",
       " ('greenback', 0.5907650589942932),\n",
       " ('Japanese_Yen', 0.5396061539649963)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('bjp', 0.5662038326263428),\n",
       " ('sonia', 0.5460007786750793),\n",
       " ('modi', 0.5448266863822937)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('English', 0.5612783432006836),\n",
       " ('Hindi', 0.5493810772895813),\n",
       " ('Institute_ITRI_eng', 0.5471854209899902)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_gensim(\"paris\", \"france\" ,\"tokyo\")[:3]\n",
    "analogy_gensim(\"usa\", \"dollar\",\"india\")[:3]\n",
    "analogy_gensim(\"germany\", \"hitler\" ,\"india\")[:3]\n",
    "analogy_gensim(\"usa\", \"english\" ,\"india\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the pretrained model to classify the news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset : E commerce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1\n",
       "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file= './../datasets/Ecommerce/ecommerceDataset.csv'\n",
    "df = pd.read_csv(dataset_file, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                               text\n",
       "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['type', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Household                 19313\n",
       "Books                     11820\n",
       "Electronics               10621\n",
       "Clothing & Accessories     8671\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "      <td>paper plane design framed wall hanging motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "      <td>saf floral framed painting wood 30 inch x 10 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "      <td>saf uv textured modern art print framed painti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "      <td>saf flower print framed painting synthetic 135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "      <td>incredible gifts india wooden happy birthday u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  ...                                           pre_text\n",
       "0  Household  ...  paper plane design framed wall hanging motivat...\n",
       "1  Household  ...  saf floral framed painting wood 30 inch x 10 i...\n",
       "2  Household  ...  saf uv textured modern art print framed painti...\n",
       "3  Household  ...  saf flower print framed painting synthetic 135...\n",
       "4  Household  ...  incredible gifts india wooden happy birthday u...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def preprocessing_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[\\s+]', ' ', text)\n",
    "    return text\n",
    "df['pre_text'] = df['text'].astype(str)\n",
    "df['pre_text'] = df['pre_text'].str.lower()\n",
    "df['pre_text'] = df['pre_text'].apply(preprocessing_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27802 entries, 0 to 27801\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   type      27802 non-null  object\n",
      " 1   text      27802 non-null  object\n",
      " 2   pre_text  27802 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 651.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper plane design framed wall hanging motivational office decor art prints 87 x 87 inch  set of 4 painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it this is an special series of paintings which makes your wall very beautiful and gives a royal touch this painting is ready to hang you would be proud to possess this unique painting that is a niche apart we use only the most modern and efficient printing technology on our prints with only the and inks and precision epson roland and hp printers this innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime we print solely with topnotch 100 inks to achieve brilliant and true colours due to their high level of uv resistance our prints retain their beautiful colours for many years add colour and style to your living space with this digitally printed painting some are for pleasure and some for eternal blissso bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and familyit would be treasured forever by whoever your lucky recipient is liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home office or any room'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27802, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27802, 27802)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['pre_text'].tolist()\n",
    "y = df['type'].tolist()\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec_path = download_word2vec_model()\n",
    "# embeddings = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "dim = embeddings.vector_size\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'plane', 'design', 'framed', 'wall', 'hanging', 'motivational', 'office', 'decor', 'art', 'prints', '87', 'x', '87', 'inch', 'set', 'of', '4', 'painting', 'made', 'up', 'in', 'synthetic', 'frame', 'with', 'uv', 'textured', 'print', 'which', 'gives', 'multi', 'effects', 'and', 'attracts', 'towards', 'it', 'this', 'is', 'an', 'special', 'series', 'of', 'paintings', 'which', 'makes', 'your', 'wall', 'very', 'beautiful', 'and', 'gives', 'a', 'royal', 'touch', 'this', 'painting', 'is', 'ready', 'to', 'hang', 'you', 'would', 'be', 'proud', 'to', 'possess', 'this', 'unique', 'painting', 'that', 'is', 'a', 'niche', 'apart', 'we', 'use', 'only', 'the', 'most', 'modern', 'and', 'efficient', 'printing', 'technology', 'on', 'our', 'prints', 'with', 'only', 'the', 'and', 'inks', 'and', 'precision', 'epson', 'roland', 'and', 'hp', 'printers', 'this', 'innovative', 'hd', 'printing', 'technique', 'results', 'in', 'durable', 'and', 'spectacular', 'looking', 'prints', 'of', 'the', 'highest', 'that', 'last', 'a', 'lifetime', 'we', 'print', 'solely', 'with', 'topnotch', '100', 'inks', 'to', 'achieve', 'brilliant', 'and', 'true', 'colours', 'due', 'to', 'their', 'high', 'level', 'of', 'uv', 'resistance', 'our', 'prints', 'retain', 'their', 'beautiful', 'colours', 'for', 'many', 'years', 'add', 'colour', 'and', 'style', 'to', 'your', 'living', 'space', 'with', 'this', 'digitally', 'printed', 'painting', 'some', 'are', 'for', 'pleasure', 'and', 'some', 'for', 'eternal', 'blissso', 'bring', 'home', 'this', 'elegant', 'print', 'that', 'is', 'lushed', 'with', 'rich', 'colors', 'that', 'makes', 'it', 'nothing', 'but', 'sheer', 'elegance', 'to', 'be', 'to', 'your', 'friends', 'and', 'familyit', 'would', 'be', 'treasured', 'forever', 'by', 'whoever', 'your', 'lucky', 'recipient', 'is', 'liven', 'up', 'your', 'place', 'with', 'these', 'intriguing', 'paintings', 'that', 'are', 'high', 'definition', 'hd', 'graphic', 'digital', 'prints', 'for', 'home', 'office', 'or', 'any', 'room'] <class 'list'> 0 skipped Household\n",
      "['sourcery'] 10424 skipped Household\n",
      "['ramayana'] 11710 skipped Books\n",
      "['nirali', 'brihanmumbai', 'mahanagarpalika', 'duyyam', 'abhiyanta', 'sthapatya'] 12005 skipped Books\n",
      "['shaley', 'bhugol', 'prashnasanch', 'spashtikarnasah', 'kuldeep', 'kamble', 'dyceo'] 12177 skipped Books\n",
      "['siddhartha'] 12739 skipped Books\n",
      "['aadhunik', 'bhartiya', 'itihas', 'evam', 'samkalin', 'vishwa', 'itihas'] 12936 skipped Books\n",
      "['chanakya', 'niti'] 13119 skipped Books\n",
      "['madhumeh', 'illaj'] 15574 skipped Books\n",
      "['iadyera'] 15789 skipped Books\n",
      "['dasham', 'chhaya', 'bhautabignan', 'sikshak', '2018'] 16204 skipped Books\n",
      "['archaeology'] 16418 skipped Books\n",
      "['kautilya', 'arthshastra'] 16610 skipped Books\n",
      "['chanakya'] 16612 skipped Books\n",
      "['prarambhik', 'bhartiy', 'itihas'] 16763 skipped Books\n",
      "['amazonbasics', '1male', 'to', '2female', 'rca', 'yadapter', '12inches'] 24624 skipped Electronics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27786, 300), 16)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[\\s+]', ' ', text)\n",
    "    return text.split()\n",
    "\n",
    "Xd = []\n",
    "skipped = []\n",
    "for i in range(len(X)):\n",
    "    if type(X[i]) != str:\n",
    "        print(X[i] , type(X[i]),i, 'skipped', y[i])\n",
    "        skipped.append(i)\n",
    "        continue\n",
    "    prep_text = preprocess(X[i])\n",
    "    emb = np.zeros(dim)\n",
    "    cnt = 0\n",
    "    for text in prep_text:\n",
    "        try:\n",
    "            ei= embeddings.get_vector(text)\n",
    "            emb += ei\n",
    "            cnt += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if cnt > 0:\n",
    "        emb /= cnt\n",
    "    else :\n",
    "        print(prep_text, i, 'skipped', y[i])\n",
    "        skipped.append(i)\n",
    "        continue\n",
    "    Xd.append(emb)\n",
    "    \n",
    "Xd = np.array(Xd)\n",
    "Xd.shape, len(skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27802,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27786,), (27786, 300))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.ones(len(y), dtype=bool)\n",
    "mask[skipped] = False\n",
    "y[mask].shape, Xd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file= './../datasets/Ecommerce/'\n",
    "\n",
    "np.save(dataset_file + 'X.npy', Xd)\n",
    "np.save(dataset_file + 'y.npy', y[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22228, 300), (5558, 300), (22228,), (5558,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(dataset_file + 'X.npy')\n",
    "y = np.load(dataset_file + 'y.npy')\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.92911119107593"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iisc",
   "language": "python",
   "name": "iisc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
