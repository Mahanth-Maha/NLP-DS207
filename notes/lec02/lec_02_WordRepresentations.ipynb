{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Model - Word2Vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset : Indian News Articles\n",
    "\n",
    "link : https://www.kaggle.com/datasets/therohk/india-headlines-news-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010102           unknown   \n",
       "1      20010102           unknown   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                Fissures in Hurriyat over Pak visit  \n",
       "2              America's unwanted heading for India?  \n",
       "3                 For bigwigs; it is destination Goa  \n",
       "4               Extra buses to clear tourist traffic  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = np.loadtxt('./data/india-news-headlines.csv', dtype=str)\n",
    "# data = data[1:]\n",
    "df = pd.read_csv('./data/india-news-headlines.csv')\n",
    "df.head( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3876557 entries, 0 to 3876556\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   publish_date       int64 \n",
      " 1   headline_category  object\n",
      " 2   headline_text      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 88.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3850912, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Status quo will not be disturbed at Ayodhya; says Vajpayee',\n",
       " 'Fissures in Hurriyat over Pak visit',\n",
       " \"America's unwanted heading for India?\",\n",
       " 'For bigwigs; it is destination Goa',\n",
       " 'Extra buses to clear tourist traffic']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentances = df['headline_text'].tolist()\n",
    "type(sentances)\n",
    "sentances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['status quo will not be disturbed at ayodhya says vajpayee',\n",
       " 'fissures in hurriyat over pak visit',\n",
       " 'americas unwanted heading for india',\n",
       " 'for bigwigs it is destination goa',\n",
       " 'extra buses to clear tourist traffic']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def pre_process_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    return text\n",
    "\n",
    "sentances = [pre_process_data(text) for text in sentances] \n",
    "sentances[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances = sentances[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128  # Embedding dimension\n",
    "m = 2    # Context window size\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_sentences = [sentence.split() for sentence in sentances]\n",
    "# tokenized_sentences[:4] , len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "# words[:4] , len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_counts = Counter(words)\n",
    "# vocab = {word: idx for idx, (word, _) in enumerate(word_counts.most_common())}\n",
    "# vocab_size = len(vocab)\n",
    "# vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = []\n",
    "# for sentence in tokenized_sentences:\n",
    "#     indices = [vocab[word] for word in sentence]\n",
    "#     for i in range(len(indices)):\n",
    "#         target = indices[i]\n",
    "#         context = indices[max(0, i - m):i] + indices[i + 1:min(len(indices), i + m + 1)]\n",
    "#         for ctx in context:\n",
    "#             pairs.append((target, ctx))\n",
    "# pairs[:4] , len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx2word = {idx: word for word, idx in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274470"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        tokenized_sentences = [sentence.split() for sentence in data]\n",
    "        self.words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "        self.word_counts = Counter(self.words)\n",
    "        self.vocab = {word: idx for idx, (word, _) in enumerate(self.word_counts.most_common())}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.word_dict = {idx: word for word, idx in self.vocab.items()}\n",
    "        \n",
    "        self.pairs = []\n",
    "        for sentence in tokenized_sentences:\n",
    "            indices = [self.vocab[word] for word in sentence]\n",
    "            for i in range(len(indices)):\n",
    "                target = indices[i]\n",
    "                context = indices[max(0, i - m):i] + indices[i + 1:min(len(indices), i + m + 1)]\n",
    "                for ctx in context:\n",
    "                    self.pairs.append((target, ctx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.pairs[idx][0], dtype=torch.long).to(device), torch.tensor(self.pairs[idx][1], dtype=torch.long).to(device)\n",
    "\n",
    "    def idx2word(self, idx):\n",
    "        return self.word_dict[idx]\n",
    "    \n",
    "dataset = SkipGramDataset(sentances)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16115"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.in_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "    def forward(self, target, context):\n",
    "        target_embed = self.in_embed(target) # (batch_size, d)\n",
    "        target_embed = target_embed.to(device)\n",
    "        context_embed = self.out_embed(context)  # (batch_size, d)\n",
    "        context_embed = context_embed.to(device)\n",
    "        scores = torch.matmul(target_embed, context_embed.T)  # (batch_size, batch_size)\n",
    "        return scores\n",
    "\n",
    "model = Word2Vec(dataset.vocab_size, d)\n",
    "model = model.to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 18.6476\n",
      "Epoch 2/2, Loss: 12.7575\n",
      "Embeddings shape: torch.Size([16115, 128])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "epochs = 2\n",
    "start_train = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    start_epoch = datetime.datetime.now()\n",
    "    for target, context in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(target, context)\n",
    "        loss = criterion(scores, torch.arange(len(target)).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    end_epoch = datetime.datetime.now()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f} Time : {end_epoch - start_epoch}\")\n",
    "end_train = datetime.datetime.now()\n",
    "print(f\"Total training time: {end_train - start_train}\")\n",
    "\n",
    "# Get final embeddings\n",
    "embeddings = model.in_embed.weight.data\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8281,  0.2208,  0.2066, -0.3692, -0.2861, -0.5029, -0.9231, -0.0129,\n",
       "        -0.2746,  0.6212, -0.2126, -0.0185,  0.1650, -0.1373,  0.1493,  0.2634,\n",
       "        -0.3162,  0.2602, -0.2889, -0.0176, -0.1919,  0.1611, -0.4257,  0.3053,\n",
       "        -0.1197,  0.8984, -0.3155, -0.3865,  0.1984,  0.2698, -0.1225,  0.1945,\n",
       "        -0.2526, -0.2370,  0.2030,  0.0103, -0.3100,  0.1015, -1.0637,  0.6350,\n",
       "         0.2944,  0.1062, -0.8214, -0.5063,  0.0519,  0.1600,  0.4495,  0.6756,\n",
       "        -0.0444,  0.7521, -0.5282, -0.3213, -0.1128, -0.8681,  0.0423,  0.2985,\n",
       "         0.4212,  0.8281, -0.9976,  0.3831,  0.2669,  0.9346,  0.1325,  0.4874,\n",
       "        -0.2070, -0.1826, -0.1507,  0.3772,  0.6873, -0.3246, -0.0659,  0.7672,\n",
       "         0.3524,  0.5708, -0.4227,  0.0271, -0.3807,  0.8528,  0.0433, -0.2789,\n",
       "         0.7951, -0.4810, -0.1612, -0.2830, -0.4202, -0.3223, -0.4604, -0.3238,\n",
       "        -0.0356,  1.0936, -0.4676,  0.2899,  0.1627, -0.0911,  0.6669, -0.2958,\n",
       "         1.6538,  0.7600, -0.0513, -0.6489,  0.2350, -0.0986,  0.7967,  0.2607,\n",
       "         0.4060,  0.2587, -0.2096,  0.1214, -0.2047, -0.2154, -0.5608,  0.0557,\n",
       "        -0.3838, -0.5291,  0.1953,  0.4016, -0.1947, -0.4898, -0.8411, -0.9462,\n",
       "         0.1620, -0.0855,  0.9769,  0.3272, -0.4377, -0.4385, -0.4150,  0.4333],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"india\"\n",
    "embedding = embeddings[dataset.vocab[word]]\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('testify', 22.02251625061035),\n",
       " ('humiliation', 20.87239646911621),\n",
       " ('e', 20.559024810791016),\n",
       " ('hoitytoity', 20.296947479248047),\n",
       " ('mouma', 20.176151275634766)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar(word, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        vec = embeddings[dataset.vocab[word]]\n",
    "        similarities = torch.matmul(embeddings, vec)\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values[1:], indices[1:])]\n",
    "    \n",
    "find_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trainers', 30.954187393188477),\n",
       " ('priests', 29.73798942565918),\n",
       " ('restriction', 29.651779174804688),\n",
       " ('allegations', 27.303354263305664),\n",
       " ('f', 26.921924591064453)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\"goa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 5.9219 Time : 0:00:58.164656\n",
      "Epoch 2/100, Loss: 4.8245 Time : 0:01:03.099172\n",
      "Epoch 3/100, Loss: 4.0234 Time : 0:00:57.366843\n",
      "Epoch 4/100, Loss: 3.4184 Time : 0:01:04.583211\n",
      "Epoch 5/100, Loss: 2.9561 Time : 0:00:58.608970\n",
      "Epoch 6/100, Loss: 2.6140 Time : 0:01:03.982722\n",
      "Epoch 7/100, Loss: 2.3386 Time : 0:00:54.838242\n",
      "Epoch 8/100, Loss: 2.1318 Time : 0:01:03.527977\n",
      "Epoch 9/100, Loss: 1.9658 Time : 0:00:56.782572\n",
      "Epoch 10/100, Loss: 1.8342 Time : 0:01:02.251838\n",
      "Epoch 11/100, Loss: 1.7314 Time : 0:00:57.739489\n",
      "Epoch 12/100, Loss: 1.6460 Time : 0:01:02.666478\n",
      "Epoch 13/100, Loss: 1.5748 Time : 0:00:55.932510\n",
      "Epoch 14/100, Loss: 1.5190 Time : 0:01:02.170413\n",
      "Epoch 15/100, Loss: 1.4716 Time : 0:00:55.336758\n",
      "Epoch 16/100, Loss: 1.4305 Time : 0:01:03.820962\n",
      "Epoch 17/100, Loss: 1.3986 Time : 0:00:57.933283\n",
      "Epoch 18/100, Loss: 1.3705 Time : 0:01:00.363841\n",
      "Epoch 19/100, Loss: 1.3478 Time : 0:00:56.754024\n",
      "Epoch 20/100, Loss: 1.3255 Time : 0:01:02.396801\n",
      "Epoch 21/100, Loss: 1.3109 Time : 0:00:56.595077\n",
      "Epoch 22/100, Loss: 1.2933 Time : 0:01:02.012648\n",
      "Epoch 23/100, Loss: 1.2806 Time : 0:00:55.504598\n",
      "Epoch 24/100, Loss: 1.2732 Time : 0:01:00.057015\n",
      "Epoch 25/100, Loss: 1.2643 Time : 0:00:58.544394\n",
      "Epoch 26/100, Loss: 1.2591 Time : 0:01:00.360655\n",
      "Epoch 27/100, Loss: 1.2483 Time : 0:00:59.710972\n",
      "Epoch 28/100, Loss: 1.2434 Time : 0:08:48.875689\n",
      "Epoch 29/100, Loss: 1.2389 Time : 0:03:01.545865\n",
      "Epoch 30/100, Loss: 1.2361 Time : 0:01:03.194629\n",
      "Epoch 31/100, Loss: 1.2278 Time : 0:00:58.689572\n",
      "Epoch 32/100, Loss: 1.2273 Time : 0:01:03.054456\n",
      "Epoch 33/100, Loss: 1.2241 Time : 0:00:56.641761\n",
      "Epoch 34/100, Loss: 1.2227 Time : 0:00:53.807926\n",
      "Epoch 35/100, Loss: 1.2172 Time : 0:00:46.072108\n",
      "Epoch 36/100, Loss: 1.2123 Time : 0:00:54.148448\n",
      "Epoch 37/100, Loss: 1.2142 Time : 0:00:57.295273\n",
      "Epoch 38/100, Loss: 1.2125 Time : 0:00:57.672103\n",
      "Epoch 39/100, Loss: 1.2096 Time : 0:00:55.288515\n",
      "Epoch 40/100, Loss: 1.2080 Time : 0:00:56.665838\n",
      "Epoch 41/100, Loss: 1.2075 Time : 0:00:57.101947\n",
      "Epoch 42/100, Loss: 1.2080 Time : 0:00:59.206322\n",
      "Epoch 43/100, Loss: 1.2032 Time : 0:00:59.155863\n",
      "Epoch 44/100, Loss: 1.2042 Time : 0:01:02.122084\n",
      "Epoch 45/100, Loss: 1.2037 Time : 0:01:03.292964\n",
      "Epoch 46/100, Loss: 1.2065 Time : 0:01:01.620635\n",
      "Epoch 47/100, Loss: 1.2044 Time : 0:01:05.469041\n",
      "Epoch 48/100, Loss: 1.2036 Time : 0:01:01.751009\n",
      "Epoch 49/100, Loss: 1.2036 Time : 0:01:01.865451\n",
      "Epoch 50/100, Loss: 1.1991 Time : 0:00:57.661518\n",
      "Epoch 51/100, Loss: 1.2013 Time : 0:00:59.834549\n",
      "Epoch 52/100, Loss: 1.2008 Time : 0:00:57.293855\n",
      "Epoch 53/100, Loss: 1.2017 Time : 0:00:59.386507\n",
      "Epoch 54/100, Loss: 1.1989 Time : 0:00:52.312131\n",
      "Epoch 55/100, Loss: 1.2002 Time : 0:00:57.818945\n",
      "Epoch 56/100, Loss: 1.2018 Time : 0:00:54.532448\n",
      "Epoch 57/100, Loss: 1.2008 Time : 0:01:02.287801\n",
      "Epoch 58/100, Loss: 1.2012 Time : 0:00:54.369650\n",
      "Epoch 59/100, Loss: 1.2022 Time : 0:00:54.896503\n",
      "Epoch 60/100, Loss: 1.2015 Time : 0:01:35.135888\n",
      "Epoch 61/100, Loss: 1.2033 Time : 0:01:19.735310\n",
      "Epoch 62/100, Loss: 1.1985 Time : 0:01:36.769637\n",
      "Epoch 63/100, Loss: 1.1997 Time : 0:01:34.720043\n",
      "Epoch 64/100, Loss: 1.1996 Time : 0:01:19.274299\n",
      "Epoch 65/100, Loss: 1.1996 Time : 0:01:24.928628\n",
      "Epoch 66/100, Loss: 1.1986 Time : 0:01:39.308117\n",
      "Epoch 67/100, Loss: 1.1997 Time : 0:01:32.105799\n",
      "Epoch 68/100, Loss: 1.2015 Time : 0:01:24.536148\n",
      "Epoch 69/100, Loss: 1.2018 Time : 0:01:26.531411\n",
      "Epoch 70/100, Loss: 1.2025 Time : 0:01:37.216773\n",
      "Epoch 71/100, Loss: 1.1992 Time : 0:01:35.481558\n",
      "Epoch 72/100, Loss: 1.2034 Time : 0:01:23.075078\n",
      "Epoch 73/100, Loss: 1.2016 Time : 0:01:24.440876\n",
      "Epoch 74/100, Loss: 1.2019 Time : 0:01:35.624619\n",
      "Epoch 75/100, Loss: 1.1992 Time : 0:01:33.624286\n",
      "Epoch 76/100, Loss: 1.2035 Time : 0:01:22.245889\n",
      "Epoch 77/100, Loss: 1.2031 Time : 0:01:28.608565\n",
      "Epoch 78/100, Loss: 1.1994 Time : 0:01:36.124463\n",
      "Epoch 79/100, Loss: 1.2040 Time : 0:01:34.857609\n",
      "Epoch 80/100, Loss: 1.2001 Time : 0:01:22.241181\n",
      "Epoch 81/100, Loss: 1.2025 Time : 0:01:27.255225\n",
      "Epoch 82/100, Loss: 1.2031 Time : 0:01:36.835242\n",
      "Epoch 83/100, Loss: 1.2040 Time : 0:01:36.559573\n",
      "Epoch 84/100, Loss: 1.2052 Time : 0:01:27.239851\n",
      "Epoch 85/100, Loss: 1.2063 Time : 0:01:21.073045\n",
      "Epoch 86/100, Loss: 1.2069 Time : 0:01:39.394359\n",
      "Epoch 87/100, Loss: 1.2020 Time : 0:01:51.290482\n",
      "Epoch 88/100, Loss: 1.2069 Time : 0:01:03.401970\n",
      "Epoch 89/100, Loss: 1.2088 Time : 0:01:05.499826\n",
      "Epoch 90/100, Loss: 1.2020 Time : 0:00:58.312718\n",
      "Epoch 91/100, Loss: 1.2061 Time : 0:01:00.115089\n",
      "Epoch 92/100, Loss: 1.2016 Time : 0:00:52.048684\n",
      "Epoch 93/100, Loss: 1.2089 Time : 0:00:56.951848\n",
      "Epoch 94/100, Loss: 1.2039 Time : 0:00:51.115030\n",
      "Epoch 95/100, Loss: 1.2092 Time : 0:01:00.454045\n",
      "Epoch 96/100, Loss: 1.2093 Time : 0:00:41.006531\n",
      "Epoch 97/100, Loss: 1.2083 Time : 0:00:50.578544\n",
      "Epoch 98/100, Loss: 1.2100 Time : 0:01:00.432662\n",
      "Epoch 99/100, Loss: 1.2057 Time : 0:00:59.422698\n",
      "Epoch 100/100, Loss: 1.2078 Time : 0:00:54.478137\n",
      "Total training time: 2:02:26.107574\n",
      "Embeddings shape: torch.Size([16115, 128])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "epochs = 100\n",
    "start_train = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    start_epoch = datetime.datetime.now()\n",
    "    for target, context in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(target, context)\n",
    "        loss = criterion(scores, torch.arange(len(target)).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    end_epoch = datetime.datetime.now()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f} Time : {end_epoch - start_epoch}\")\n",
    "end_train = datetime.datetime.now()\n",
    "print(f\"Total training time: {end_train - start_train}\")\n",
    "\n",
    "# Get final embeddings\n",
    "embeddings = model.in_embed.weight.data\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100 epochs\n",
    "* Total training time: 2:02:26.107574\n",
    "* Embeddings shape: torch.Size([16115, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0194,  0.3255,  0.0346,  0.0183,  0.1571,  0.0103, -0.1187,  0.0466,\n",
       "         0.4334,  0.0987, -0.3504, -0.3079, -0.0638,  0.2358,  0.0409,  0.0637,\n",
       "        -0.2056,  0.0773,  0.2327,  0.0081, -0.1010,  0.1506, -0.2580, -0.1388,\n",
       "        -0.1459,  0.3029, -0.0941,  0.0629, -0.3272, -0.4064, -0.3322,  0.4888,\n",
       "         0.0069, -0.0429, -0.3430,  0.2600,  0.0395,  0.0536, -0.2117,  0.1122,\n",
       "         0.1337, -0.0182, -0.0374,  0.2303, -0.0293,  0.0690,  0.1730, -0.2067,\n",
       "        -0.1530,  0.4344, -0.0104, -0.1476,  0.0397,  0.2683,  0.2841,  0.3988,\n",
       "         0.3831,  0.2640, -0.2403,  0.0968, -0.2361,  0.2960,  0.4244,  0.0815,\n",
       "        -0.2283, -0.1886,  0.0197, -0.0378,  0.1208, -0.2162, -0.0120, -0.0064,\n",
       "        -0.0338, -0.0991,  0.1906, -0.1373, -0.1937,  0.2037, -0.5391,  0.0145,\n",
       "        -0.0810,  0.0641, -0.1783, -0.3374, -0.1284,  0.0445,  0.0844, -0.3269,\n",
       "         0.1566,  0.1763, -0.1409,  0.2428,  0.4478,  0.0144,  0.1651, -0.1897,\n",
       "         0.2562,  0.0517,  0.0119, -0.3784,  0.1839,  0.0716,  0.1738,  0.1333,\n",
       "        -0.1189,  0.0563,  0.0170,  0.2123,  0.0846,  0.3172, -0.1436,  0.0371,\n",
       "         0.0385, -0.0881,  0.0870, -0.0918,  0.0753, -0.1784,  0.3104, -0.3132,\n",
       "         0.1009, -0.2969, -0.0463, -0.2171, -0.0913, -0.0601, -0.4225,  0.3867],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"india\"\n",
    "embedding = embeddings[dataset.vocab[word]]\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nawruz', 9.902406692504883),\n",
       " ('singareni', 9.812178611755371),\n",
       " ('septuplets', 9.148886680603027),\n",
       " ('diagnostic', 9.141351699829102),\n",
       " ('plough', 8.840997695922852)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 0.4843333661556244),\n",
       " ('pm', 0.44458457827568054),\n",
       " ('it', 0.4277379512786865),\n",
       " ('talks', 0.41505417227745056),\n",
       " ('its', 0.400892972946167)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_cosine(word, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        vec = embeddings[dataset.vocab[word]]\n",
    "        similarities = torch.matmul(embeddings, vec) / (torch.norm(embeddings, dim=1) * torch.norm(vec))\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values[1:], indices[1:])]\n",
    "\n",
    "find_similar_cosine(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ministers', 0.33838722109794617),\n",
       " ('fashions', 0.3322593569755554),\n",
       " ('set', 0.3311415910720825),\n",
       " ('at', 0.32622039318084717),\n",
       " ('new', 0.3222562074661255)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_cosine(\"goa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 0.4343026280403137),\n",
       " ('as', 0.42826682329177856),\n",
       " ('set', 0.407269150018692),\n",
       " ('down', 0.4007364809513092),\n",
       " ('chief', 0.40044018626213074)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_cosine(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7592395544052124),\n",
       " ('fests', 0.33734554052352905),\n",
       " ('expired', 0.31791630387306213),\n",
       " ('landmine', 0.31200072169303894),\n",
       " ('lethal', 0.29223430156707764),\n",
       " ('2612', 0.2892310321331024)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 =  embeddings[dataset.vocab[\"man\"]]\n",
    "w2 =  embeddings[dataset.vocab[\"king\"]]\n",
    "w3 =  embeddings[dataset.vocab[\"queen\"]]\n",
    "w4 = w1 - w2 + w3\n",
    "def find_similar_cosine_vec(vec, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        similarities = torch.matmul(embeddings, vec) / (torch.norm(embeddings, dim=1) * torch.norm(vec))\n",
    "        values, indices = torch.topk(similarities, top_k+1)\n",
    "        return [(dataset.idx2word(idx.item()), val.item()) for val, idx in zip(values, indices)]\n",
    "\n",
    "find_similar_cosine_vec(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fests', 0.33734554052352905),\n",
       " ('expired', 0.31791630387306213),\n",
       " ('landmine', 0.31200072169303894),\n",
       " ('lethal', 0.29223430156707764),\n",
       " ('2612', 0.2892310321331024)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(word1, word2, word3):\n",
    "    w1 = embeddings[dataset.vocab[word1]]\n",
    "    w2 = embeddings[dataset.vocab[word2]]\n",
    "    w3 = embeddings[dataset.vocab[word3]]\n",
    "    w4 = w2 - w1 + w3\n",
    "    embs =  find_similar_cosine_vec(w4)\n",
    "    return [emb for emb in embs if emb[0] not in [word1, word2, word3]] \n",
    "\n",
    "analogy(\"king\", \"man\" ,\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = './model_parameters/'\n",
    "# np.save(folder + 'embeddings.npy', embeddings.cpu().numpy()) \n",
    "# np.save(folder + 'vocab.npy', dataset.vocab)\n",
    "# np.save(folder + 'word_dict.npy', dataset.word_dict)\n",
    "# np.save(folder + 'word_counts.npy', dataset.word_counts)\n",
    "# np.save(folder + 'pairs.npy', dataset.pairs)\n",
    "# np.save(folder + 'words.npy', dataset.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './model_parameters/'\n",
    "embeddings = torch.tensor(np.load(folder + 'embeddings.npy')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram - pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading word2vec-google-news-300...\n",
      "Model downloaded successfully to: C:\\Users\\myalla/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "def download_word2vec_model(model_name=\"word2vec-google-news-300\"):\n",
    "    try:\n",
    "        # Check if model is available\n",
    "        available_models = api.info()['models'].keys()\n",
    "        if model_name not in available_models:\n",
    "            raise ValueError(\n",
    "                f\"Model '{model_name}' not found. Available models: {', '.join(available_models)}\"\n",
    "            )\n",
    "\n",
    "        print(f\"Downloading {model_name}...\")\n",
    "        model_path = api.load(model_name, return_path=True)\n",
    "        print(f\"Model downloaded successfully to: {model_path}\")\n",
    "\n",
    "        return model_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "word2vec_path = download_word2vec_model()\n",
    "embeddings = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indian', 0.6967039704322815),\n",
       " ('usa', 0.6836211085319519),\n",
       " ('pakistan', 0.681516706943512),\n",
       " ('chennai', 0.6675503253936768),\n",
       " ('america', 0.6589399576187134),\n",
       " ('sri_lanka', 0.64982008934021),\n",
       " ('canada', 0.6490967869758606),\n",
       " ('australia', 0.6368584036827087),\n",
       " ('mexico', 0.6239137649536133),\n",
       " ('uk', 0.6221641898155212)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300517559051514),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676352500916),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613663792610168),\n",
       " ('sultan', 0.5376775860786438),\n",
       " ('Queen_Consort', 0.5344247817993164),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = embeddings.get_vector(\"king\")\n",
    "w2 = embeddings.get_vector(\"man\")\n",
    "w3 = embeddings.get_vector(\"woman\")\n",
    "\n",
    "w4 = w1 - w2 + w3\n",
    "\n",
    "embeddings.similar_by_vector(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7186801433563232),\n",
       " ('girl', 0.5882835388183594),\n",
       " ('lady', 0.5754351615905762),\n",
       " ('teenage_girl', 0.5700528025627136),\n",
       " ('teenager', 0.5378326177597046),\n",
       " ('schoolgirl', 0.497780978679657),\n",
       " ('policewoman', 0.49065014719963074),\n",
       " ('blonde', 0.4870774745941162),\n",
       " ('redhead', 0.4778464436531067)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy_gensim(word1, word2, word3):\n",
    "    w1 = embeddings.get_vector(word1)\n",
    "    w2 = embeddings.get_vector(word2)\n",
    "    w3 = embeddings.get_vector(word3)\n",
    "    w4 = w2 - w1 + w3\n",
    "    embs =  embeddings.similar_by_vector(w4)\n",
    "    return [emb for emb in embs if emb[0] not in [word1, word2, word3]] \n",
    "\n",
    "analogy_gensim(\"king\", \"man\" ,\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('japan', 0.5214436054229736),\n",
       " ('hong_kong', 0.46592071652412415),\n",
       " ('japanese', 0.4565887153148651)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('rupee', 0.6182144284248352),\n",
       " ('greenback', 0.5907650589942932),\n",
       " ('Japanese_Yen', 0.5396061539649963)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('bjp', 0.5662038326263428),\n",
       " ('sonia', 0.5460007786750793),\n",
       " ('modi', 0.5448266863822937)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('English', 0.5612783432006836),\n",
       " ('Hindi', 0.5493810772895813),\n",
       " ('Institute_ITRI_eng', 0.5471854209899902)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_gensim(\"paris\", \"france\" ,\"tokyo\")[:3]\n",
    "analogy_gensim(\"usa\", \"dollar\",\"india\")[:3]\n",
    "analogy_gensim(\"germany\", \"hitler\" ,\"india\")[:3]\n",
    "analogy_gensim(\"usa\", \"english\" ,\"india\")[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iisc",
   "language": "python",
   "name": "iisc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
